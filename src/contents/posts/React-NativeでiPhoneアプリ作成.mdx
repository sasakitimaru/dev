---
title: React-NativeでiPhoneアプリ作成
icon: 🗣️
description: React-NativeでiPhoneアプリ作成
date: "2023-06-07"
categories:
  - React-Native
  - iOS
  - TypeScript
---

# React-Native で iPhone アプリ作成

## 開発の経緯

今回は掲題の通り、React-Native を用いて AI と英会話をする iPhone アプリを開発しました。

<div className="flex items-center justify-center">
  <div key={1} className="mr-4">
    <Image
      src="/posts/leettalk1.png"
      width="200"
      height="400"
      alt="leettalk1"
    />
  </div>
  <div key={1}>
    <Image src="/posts/leettalk.png" width="200" height="400" alt="leettalk" />
  </div>
</div>

こんな感じでトピックを決めて AI と英会話ができ、文章をよりナチュラルに直してくれるものです。
なぜ React-Native なのかは、React が使えるからです。TypeScript ベースで開発できるのはかなりメリットなんじゃないかなと考えてました。あとはクロスプラットフォームでもありますね。

## 技術構成

### 言語

TypeScript, NodeJS, Swift, Python

### フレームワーク

**React-Native**

React-Native に便利なライブラリが揃っていて、基本的な機能はカバーしていると思います。
テキストエリアとかはもちろん、トグルのボタンとか Modal とか Alert とか…
逆に言えば少し応用したことはできないです。ネイティブのレイヤの深いところに触れたりする機能は Swift で書かないと実装できない部分もあります。
実際に自分は、音声入力に合わせて動くアニメーションを作りたかったのですが
React-Native ではそのようなライブラリはなく、自分で Swift でコードを書いて実行するしかなかったです。
ちなみに、超簡単にどうやって React-Native でネイティブコードを実行しているのかというと JavaScript のコードがネイティブのランタイムと通信するためのブリッジというものがあり、このブリッジを通じてネイティブコードと通信し、ネイティブ API を呼び出すことができます。

### バックエンド

![スクリーンショット 2023-06-15 21.32.11.png](React-Native%E3%81%A6%E3%82%99iPhone%E3%82%A2%E3%83%95%E3%82%9A%E3%83%AA%E4%BD%9C%E6%88%90%204530fade74734448a4b2204990508b79/%25E3%2582%25B9%25E3%2582%25AF%25E3%2583%25AA%25E3%2583%25BC%25E3%2583%25B3%25E3%2582%25B7%25E3%2583%25A7%25E3%2583%2583%25E3%2583%2588_2023-06-15_21.32.11.png)

**Cognito**：ユーザ認証の管理

**DynamoDB**：ユーザ情報の管理（会話データや使用データ数など）

**APIGateWay, Lambda**：各エンドポイントへのリクエストの処理

**AWS Amplify**：バックエンドの連携・テンプレート化、コードによる管理

Amplify という SDK がすごくて、簡単にバックエンドのリソースを管理できます。
フロントエンドの開発環境で Amplify CLI で利用したい AWS のリソースを選択し、実行するだけでフロントエンドと統合されます。
その後は CloudFormation を通してコードのテンプレートを作成し、それを自分でカスタマイズしていくだけです。環境の準備が一瞬で完了します。マジで凄い。。。
一つ注意点は、CLI を通して環境をいじっているのに変に GUI（マネジメントコンソール）でリソースの設定を変更したりすると不整合が起きます。実際に自分も、Cognito のアプリケーションクライアントをいじって一生 Amplify 側と整合性が取れなくなりました 😇

### 外部の API

- **ChatGPT**
  説明するまでもないですが、会話の生成の生成をしています。
  こいつがなきゃこのアプリは成り立ちません。
- **CorrectGrammer**
  文章の校正を行なっています。正直そんなに精度高いとは思いませんが、基本的な文法は直してくれます。あまりに英語力の低い回答をするとこいつではどうにもなりません。笑
- **Whisper**
  音声認識に使います。めちゃくちゃ精度高いです。結構雑音入ったり、間が長くてもへっちゃらです。実は React-Native にも音声認識して文字起こしできるものはあって、そっちはすごくレスポンス早いんですが細かいニュアンス（会話の切れ目や？など）を理解できないのでこちらを利用しています。
- **Elevenlabs**
  音声の読み上げを行います。これがまあナチュラルで、すごいです。みんなあんまり使わないで欲しいです（利用料が高い 😇）

## 大変だった箇所

山ほどありますが特に音声ファイルの扱いは難しかったです。
Elevenlabs の API をどうしても使いたかったんですが、
音声をエンコードしてから API でやり取り
→ もらったものを音声データとしてファイルにしてローカルに保存
→ 音声の再生
という手順がとても面倒でした。
音声の再生に関しては、シミュレーターではうまくいくのに実機でうまくいかなかったり（ネイティブのオーディオの制御が原因）React-Native のライブラリがどれも古かったりで散々でした。。

## React-Native を使った感想

結論から言ってしまうと使うのはあまりお勧めできないです。
コミュニティの元気がないのが１番の理由です。ライブラリが古く更新されていないものが多かったり、すでに新しいバージョンの機能とかにはキャッチアップできていないような印象を受けました。（個人の感想です）
ただそれでも、TypeScript を使って React ベースで開発できるのはとても大きなメリットだと思います。
実際、自分はこれを通して初めて TypeScript を触ったのですがかなり勉強になりましたしその後 NextJS を使ってみた時にもコンポーネントで分割して管理する、という基本的な開発の作法？のようなところがすんなり理解できました。
なんか iPhone アプリ作りたいけどネイティブ言語は学習コスト高いな〜ていう人にはお勧めです。それともそれでも Flutter とかの方がいいんですかね。自分は使ったことないので有識者の方はぜひご意見ください。

また以下の個別の実装については今後詳しく記事を書いていこうと考えてますので、ぜひご一読いただけますと幸いです。

- React-Native でのユーザ登録フォームの作成
- React-Native での音声認識の実装
- DynamoDB の GraphQL による操作
- Amplify を使ったフロントエンドとバックエンドの統合

以上、読んでいただきありがとうございました。ぜひダウンロードしていただけますと幸いです。

[‎LeetTalk](https://apps.apple.com/jp/app/leettalk/id6448966582)

See you later👋
